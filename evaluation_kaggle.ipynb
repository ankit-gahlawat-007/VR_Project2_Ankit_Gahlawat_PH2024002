{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11837033,"sourceType":"datasetVersion","datasetId":7436784},{"sourceId":11839135,"sourceType":"datasetVersion","datasetId":7438343},{"sourceId":397197,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":325718,"modelId":346563}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Base model","metadata":{}},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nimport pandas as pd\nfrom PIL import Image\nfrom transformers import ViltProcessor, ViltForQuestionAnswering\nimport torch\nimport re\n\ndef normalize_answer(ans):\n    # Lowercase\n    ans = ans.lower()\n    # Split on underscores\n    tokens = ans.split('_')\n    # Split camelCase in each token\n    final_tokens = []\n    for token in tokens:\n        camel_split = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', token).split()\n        final_tokens.extend(camel_split)\n    # Join into a single string\n    return ' '.join(final_tokens)\n\n\n# Load model and processor\nprocessor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\nmodel = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load data\nwith open(\"/kaggle/input/abo-vqa-dataset/input/test/qna_test.json\", \"r\") as f:\n    data = json.load(f)\n\nroot_img_dir = \"/kaggle/input/abo-vqa-dataset/input/test/images_test\"  # top-level folder where /images is stored\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Run inference\npredictions = []\nskipped_items = []\n\nfor item in data:\n    try:\n        image_path = os.path.join(root_img_dir, item[\"image_path\"].lstrip(\"/\"))\n        image = Image.open(image_path).convert(\"RGB\")\n        question = item[\"question\"]\n        answer = normalize_answer(item[\"answer\"])\n\n        inputs = processor(image, question, return_tensors=\"pt\").to(device)\n        outputs = model(**inputs)\n        logits = outputs.logits\n        predicted_idx = logits.argmax(-1).item()\n        predicted_answer = model.config.id2label[predicted_idx]\n\n        predictions.append({\n            \"image_id\": item[\"image_id\"],\n            \"question\": question,\n            \"answer\": answer,\n            \"generated_answer\": predicted_answer\n        })\n\n    except FileNotFoundError:\n        # print(f\"[Missing Image] Skipping item with image_path: {item['image_path']}\")\n        skipped_items.append(item)\n    except Exception as e:\n        print(f\"[Error] Skipping item due to: {e}\")\n        skipped_items.append(item)\n\n# Create DataFrame\ndf = pd.DataFrame(predictions)\ndf.to_csv(\"results.csv\")\nprint(f\"Total items {len(data)}, skipped items: {len(skipped_items)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T14:57:28.436752Z","iopub.execute_input":"2025-05-16T14:57:28.437375Z","iopub.status.idle":"2025-05-16T14:58:51.979457Z","shell.execute_reply.started":"2025-05-16T14:57:28.437348Z","shell.execute_reply":"2025-05-16T14:58:51.978751Z"},"_kg_hide-output":true},"outputs":[{"name":"stderr","text":"2025-05-16 14:57:45.036069: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747407465.272723      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747407465.345073      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/251 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"378d13c5053f44f09263a68bc024e1f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c35fdb6323b74b368fba71e386b70c4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b61b16261864e328ca3adb05cc410e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8899113efbf47a190d36babdc89b937"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04a07280477a42c18e05e31756507df3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/136k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2688828462425aaeee43b5156af32a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e9a26981c124609884721b18b6e73e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/470M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56331e7a58e84ff0b2d4195cf45a7e3b"}},"metadata":{}},{"name":"stdout","text":"Total items 1490, skipped items: 0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Evaluation (BERTScore and BARTScore)","metadata":{}},{"cell_type":"code","source":"pip install bert-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:20:47.210475Z","iopub.execute_input":"2025-05-16T17:20:47.211122Z","iopub.status.idle":"2025-05-16T17:22:13.425171Z","shell.execute_reply.started":"2025-05-16T17:20:47.211096Z","shell.execute_reply":"2025-05-16T17:22:13.423956Z"},"_kg_hide-input":true,"scrolled":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.6.0+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.51.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert-score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert-score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score) (3.7.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert-score) (25.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert-score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert-score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->bert-score)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score) (0.5.3)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert-score) (2025.4.26)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers>=3.0.0->bert-score) (1.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert-score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert-score) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert-score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert-score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bert-score\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed bert-score-0.3.13 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom bert_score import score as bert_score\nfrom transformers import BartTokenizer, BartForConditionalGeneration\n\n# Prepare refs and hyps\nrefs = df[\"answer\"].astype(str).tolist()\nhyps = df[\"generated_answer\"].astype(str).tolist()\n\ndf[\"is_correct\"] = df[\"answer\"] == df[\"generated_answer\"]\naccuracy = df[\"is_correct\"].mean()\nprint(f\"Exact Match Accuracy: {accuracy:.4f}\")\n\n# BERTScore\nP, R, F1 = bert_score(hyps, refs, lang=\"en\", rescale_with_baseline=True)\ndf[\"bertscore_f1\"] = F1.tolist()\nmean_bertscore = F1.mean().item()\nprint(f\"{mean_bertscore=}\")\n\n# BARTScore\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\nbart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\nbart_model.eval()\n\ndef compute_bartscore(hyp, ref):\n    with torch.no_grad():\n        input_ids = tokenizer(hyp, return_tensors=\"pt\").input_ids.to(device)\n        labels = tokenizer(ref, return_tensors=\"pt\").input_ids.to(device)\n        outputs = bart_model(input_ids=input_ids, labels=labels)\n        return -outputs.loss.item()  # log-likelihood (higher = better)\n\n# Compute BARTScore for each sample\nbart_scores = [compute_bartscore(h, r) for h, r in zip(hyps, refs)]\ndf[\"bartscore\"] = bart_scores\nmean_bartscore = np.mean(bart_scores)\nprint(f\"{mean_bartscore=}\")\n\n\nprint(\"-------------\")\nprint(f\"Mean BERTScore (F1): {mean_bertscore:.4f}\")\nprint(f\"Mean BARTScore    : {mean_bartscore:.4f}\")\nprint(f\"Exact Match Acc.  : {accuracy:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:01:15.344741Z","iopub.execute_input":"2025-05-16T15:01:15.345017Z","iopub.status.idle":"2025-05-16T15:01:46.986300Z","shell.execute_reply.started":"2025-05-16T15:01:15.344992Z","shell.execute_reply":"2025-05-16T15:01:46.985540Z"}},"outputs":[{"name":"stdout","text":"Exact Match Accuracy: 0.1047\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\n","output_type":"stream"},{"name":"stdout","text":"mean_bertscore=0.4109959900379181\nmean_bartscore=-5.987912863052931\n-------------\nMean BERTScore (F1): 0.4110\nMean BARTScore    : -5.9879\nExact Match Acc.  : 0.1047\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# Labels for scikit-learn must be exact matches of all possible classes\ny_true = df[\"answer\"]\ny_pred = df[\"generated_answer\"]\n\n# If you're dealing with multiple possible labels, use macro or weighted average\nprecision = precision_score(y_true, y_pred, average=\"micro\")\nrecall = recall_score(y_true, y_pred, average=\"micro\")\nf1 = f1_score(y_true, y_pred, average=\"micro\")\n\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T15:03:23.988101Z","iopub.execute_input":"2025-05-16T15:03:23.988402Z","iopub.status.idle":"2025-05-16T15:03:24.042045Z","shell.execute_reply.started":"2025-05-16T15:03:23.988379Z","shell.execute_reply":"2025-05-16T15:03:24.041475Z"}},"outputs":[{"name":"stdout","text":"Precision: 0.1047\nRecall   : 0.1047\nF1 Score : 0.1047\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Finetuned ViLT","metadata":{}},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"import os\nos.getcwd()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:16:33.365826Z","iopub.execute_input":"2025-05-16T17:16:33.366714Z","iopub.status.idle":"2025-05-16T17:16:33.372728Z","shell.execute_reply.started":"2025-05-16T17:16:33.366682Z","shell.execute_reply":"2025-05-16T17:16:33.372009Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import ViltProcessor, ViltConfig, ViltForQuestionAnswering\nfrom peft import PeftModel\nfrom PIL import Image\nimport torch\nimport json\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport re\n\ndef normalize_answer(ans):\n    # Lowercase\n    ans = ans.lower()\n    # Split on underscores\n    tokens = ans.split('_-')\n    # Split camelCase in each token\n    final_tokens = []\n    for token in tokens:\n        camel_split = re.sub(r'([a-z])([A-Z])', r'\\1 \\2', token).split()\n        final_tokens.extend(camel_split)\n    # Join into a single string\n    return ' '.join(final_tokens)\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# ✅ Load processor and config from finetuned LoRA folder\n# processor = ViltProcessor.from_pretrained(\"vilt-finetuned-vqa\")\n# config = ViltConfig.from_pretrained(\"vilt-finetuned-vqa\")  # Must include correct num_labels = 841\nprocessor = ViltProcessor.from_pretrained(\"/kaggle/input/vilt-finetuned/vilt-finetuned-vqa\")\nconfig = ViltConfig.from_pretrained(\"/kaggle/input/vilt-finetuned/vilt-finetuned-vqa\")  # Must include correct num_labels = 841\n\n# ✅ Load base model with config — but DO NOT load weights from vilt-finetuned-vqa\nbase_model = ViltForQuestionAnswering.from_pretrained(\n    \"dandelin/vilt-b32-finetuned-vqa\",\n    config=config,\n    ignore_mismatched_sizes=True\n)\n\n# ✅ Attach the LoRA adapter trained on top of this config\n# model = PeftModel.from_pretrained(base_model, \"/kaggle/input/vilt-fintuned-vqa/transformers/default/1/vilt-finetuned-vqa\")\nmodel = PeftModel.from_pretrained(base_model, \"/kaggle/input/vilt-finetuned/vilt-finetuned-vqa\")\n\n\nmodel.to(device)\nmodel.eval()\n\n# Load data\nwith open(\"/kaggle/input/abo-vqa-dataset/input/test/qna_test.json\", \"r\") as f:\n    data = json.load(f)\n\nroot_img_dir = \"/kaggle/input/abo-vqa-dataset/input/test/images_test\"  # top-level folder where /images is stored\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Run inference\npredictions = []\nskipped_items = []\n\nfor item in data:\n    try:\n        image_path = os.path.join(root_img_dir, item[\"image_path\"].lstrip(\"/\"))\n        image = Image.open(image_path).convert(\"RGB\")\n        question = item[\"question\"]\n        answer = normalize_answer(item[\"answer\"])\n\n        inputs = processor(image, question, return_tensors=\"pt\").to(device)\n        outputs = model(**inputs)\n        logits = outputs.logits\n        predicted_idx = logits.argmax(-1).item()\n        predicted_answer = model.config.id2label[predicted_idx]\n\n        predictions.append({\n            \"image_id\": item[\"image_id\"],\n            \"question\": question,\n            \"answer\": answer,\n            \"generated_answer\": normalize_answer(predicted_answer)\n        })\n\n    except FileNotFoundError:\n        # print(f\"[Missing Image] Skipping item with image_path: {item['image_path']}\")\n        skipped_items.append(item)\n    except Exception as e:\n        print(f\"[Error] Skipping item due to: {e}\")\n        skipped_items.append(item)\n\n# Create DataFrame\ndf1 = pd.DataFrame(predictions)\ndf1.to_csv(\"ft-results.csv\")\nprint(f\"Total items {len(data)}, skipped items: {len(skipped_items)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:52:14.484973Z","iopub.execute_input":"2025-05-16T17:52:14.485977Z","iopub.status.idle":"2025-05-16T17:53:08.969271Z","shell.execute_reply.started":"2025-05-16T17:52:14.485939Z","shell.execute_reply":"2025-05-16T17:53:08.968215Z"}},"outputs":[{"name":"stderr","text":"Some weights of ViltForQuestionAnswering were not initialized from the model checkpoint at dandelin/vilt-b32-finetuned-vqa and are newly initialized because the shapes did not match:\n- classifier.3.weight: found shape torch.Size([3129, 1536]) in the checkpoint and torch.Size([1964, 1536]) in the model instantiated\n- classifier.3.bias: found shape torch.Size([3129]) in the checkpoint and torch.Size([1964]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Total items 1490, skipped items: 0\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"### Evaluation","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom bert_score import score as bert_score\nfrom transformers import BartTokenizer, BartForConditionalGeneration\n\n# Prepare refs and hyps\nrefs = df1[\"answer\"].astype(str).tolist()\nhyps = df1[\"generated_answer\"].astype(str).tolist()\n\ndf1[\"is_correct\"] = df1[\"answer\"] == df1[\"generated_answer\"]\naccuracy = df1[\"is_correct\"].mean()\nprint(f\"Exact Match Accuracy: {accuracy:.4f}\")\n\n# BERTScore\nP, R, F1 = bert_score(hyps, refs, lang=\"en\", rescale_with_baseline=True)\ndf1[\"bertscore_f1\"] = F1.tolist()\nmean_bertscore = F1.mean().item()\nprint(f\"{mean_bertscore=}\")\n\n# BARTScore\ntokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\nbart_model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\").to(device)\nbart_model.eval()\n\ndef compute_bartscore(hyp, ref):\n    with torch.no_grad():\n        input_ids = tokenizer(hyp, return_tensors=\"pt\").input_ids.to(device)\n        labels = tokenizer(ref, return_tensors=\"pt\").input_ids.to(device)\n        outputs = bart_model(input_ids=input_ids, labels=labels)\n        return -outputs.loss.item()  # log-likelihood (higher = better)\n\n# Compute BARTScore for each sample\nbart_scores = [compute_bartscore(h, r) for h, r in zip(hyps, refs)]\ndf1[\"bartscore\"] = bart_scores\nmean_bartscore = np.mean(bart_scores)\nprint(f\"{mean_bartscore=}\")\n\n\nprint(\"-------------\")\nprint(f\"Mean BERTScore (F1): {mean_bertscore:.4f}\")\nprint(f\"Mean BARTScore    : {mean_bartscore:.4f}\")\nprint(f\"Exact Match Acc.  : {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T17:53:08.971118Z","iopub.execute_input":"2025-05-16T17:53:08.971377Z","iopub.status.idle":"2025-05-16T17:53:46.613466Z","shell.execute_reply.started":"2025-05-16T17:53:08.971358Z","shell.execute_reply":"2025-05-16T17:53:46.612524Z"}},"outputs":[{"name":"stdout","text":"Exact Match Accuracy: 0.4913\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\nWarning: Empty reference sentence detected; setting raw BERTScores to 0.\n","output_type":"stream"},{"name":"stdout","text":"mean_bertscore=0.6480774879455566\nmean_bartscore=-4.223890054905975\n-------------\nMean BERTScore (F1): 0.6481\nMean BARTScore    : -4.2239\nExact Match Acc.  : 0.4913\n","output_type":"stream"}],"execution_count":10}]}